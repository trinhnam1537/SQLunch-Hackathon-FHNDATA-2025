services:

  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse
    ports:
      - "8123:8123"   # HTTP (ClickHouse UI / clients)
      - "9000:9000"   # Native protocol
    networks:
      - bigdata-net
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - clickhouse_logs:/var/log/clickhouse-server
      - ./clickhouse-config/users.d:/etc/clickhouse-server/users.d


  kafka-1:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka-1
    ports:
      - "9092:9092"
    networks:
      - bigdata-net
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:29093,2@kafka-2:29093,3@kafka-3:29093"
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:29093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      CLUSTER_ID: "LcA1iuWfRzazY6P1DcJSWA=="
      KAFKA_LOG_DIRS: /var/lib/kafka/data

    mem_limit: 1200m
    cpus: 1.0

  kafka-2:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka-2
    ports:
      - "9094:9092"
    networks:
      - bigdata-net
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:29093,2@kafka-2:29093,3@kafka-3:29093"
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:29093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9094
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      CLUSTER_ID: "LcA1iuWfRzazY6P1DcJSWA=="
      KAFKA_LOG_DIRS: /var/lib/kafka/data

    mem_limit: 1200m
    cpus: 1.0

  kafka-3:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka-3
    ports:
      - "9095:9092"

    networks:
      - bigdata-net
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:29093,2@kafka-2:29093,3@kafka-3:29093"
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:29093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9095
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      CLUSTER_ID: "LcA1iuWfRzazY6P1DcJSWA=="
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    mem_limit: 1200m
    cpus: 1.0


  redis:
    image: redis:7
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - bigdata-net
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping | grep PONG || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 12
    restart: unless-stopped

# #new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  
# #new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  
# #new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  
# #new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  new shit  
#   minio:
#     image: minio/minio:latest
#     container_name: minio
#     networks:
#       - bigdata-net
#     environment:
#       MINIO_ROOT_USER: admin
#       MINIO_ROOT_PASSWORD: namvudit
#     command: server /data --console-address ":9001"
#     ports:
#       - "6767:9000"   # S3 API
#       - "9001:9001"   # Console UI
#     volumes:
#       - minio_data:/data

#   spark-master:
#     build:
#       context: ./batch_pipeline/spark_dockerfile
#     container_name: spark-master
#     user: "0:0"
#     command: >
#       bash -c "
#       /opt/spark/sbin/start-master.sh;
#       tail -f /opt/spark/logs/spark*.out
#       "
#     environment:
#       - SPARK_MASTER_MEMORY=${SPARK_DAEMON_MEMORY:-1g}
#       - SPARK_MASTER_OPTS=-Dspark.deploy.recoveryMode=NONE
#       - SPARK_NO_DAEMONIZE=true
#     ports:
#       - "${SPARK_MASTER_WEBUI_PORT:-1990}:8080"   # Master UI
#       - "${SPARK_MASTER_PORT:-7077}:7077"   # Master RPC
#     networks:
#       - bigdata-net
#     volumes:
#       - ./batch_pipeline/apps:/opt/spark/apps:ro
#       - ./batch_pipeline/data:/opt/spark/data
#       - ./batch_pipeline/events:/events
#       - ./batch_pipeline/conf/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf:ro
#       - ./batch_pipeline/conf/log4j2.properties:/opt/spark/conf/log4j2.properties:ro
#       - ./batch_pipeline/conf/metrics.properties:/opt/spark/conf/metrics.properties:ro
#       - spark-recovery:/tmp/spark-recovery
#     restart: unless-stopped
#     healthcheck:
#       test: ["CMD", "bash", "-c", "exec 3<>/dev/tcp/localhost/8080 && echo -e 'GET / HTTP/1.1\r\nHost: localhost\r\nConnection: close\r\n\r\n' >&3 && head -1 <&3 | grep -q '200 OK'"]
#       interval: 10s
#       timeout: 5s
#       retries: 5
#       start_period: 30s

#   spark-worker:
#     build:
#       context: ./batch_pipeline/spark_dockerfile
#     user: "0:0"
#     depends_on:
#       spark-master:
#         condition: service_healthy
#     command: >
#       bash -c "
#       /opt/spark/sbin/start-worker.sh spark://spark-master:${SPARK_MASTER_PORT:-7077};
#       tail -f /opt/spark/logs/spark*.out
#       "
#     environment:
#       - SPARK_WORKER_MEMORY=${SPARK_WORKER_MEMORY:-2G}
#       - SPARK_WORKER_CORES=${SPARK_WORKER_CORES:-2}
#       - SPARK_WORKER_OPTS=-Dspark.worker.cleanup.enabled=true -Dspark.worker.cleanup.interval=1800
#       - SPARK_NO_DAEMONIZE=true
#     deploy:
#       replicas: ${SPARK_WORKER_REPLICAS:-1}
#       resources:
#         limits:
#           memory: ${SPARK_WORKER_MEMORY:-2G}
#           cpus: '${SPARK_WORKER_CORES:-2}'
#         reservations:
#           memory: 2G
#           cpus: '1'
#     networks:
#       - bigdata-net
#     volumes:
#       - ./batch_pipeline/apps:/opt/spark/apps:ro
#       - ./batch_pipeline/data:/opt/spark/data
#       - ./batch_pipeline/events:/events
#       - ./batch_pipeline/conf/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf:ro
#       - ./batch_pipeline/conf/log4j2.properties:/opt/spark/conf/log4j2.properties:ro
#       - ./batch_pipeline/conf/metrics.properties:/opt/spark/conf/metrics.properties:ro
#     restart: unless-stopped
#     healthcheck:
#       test: ["CMD", "bash", "-c", "exec 3<>/dev/tcp/localhost/8081 && echo -e 'GET / HTTP/1.1\r\nHost: localhost\r\nConnection: close\r\n\r\n' >&3 && head -1 <&3 | grep -q '200 OK'"]
#       interval: 15s
#       timeout: 5s
#       retries: 3
#       start_period: 45s

#   spark-history-server:
#     build:
#       context: ./batch_pipeline/spark_dockerfile
#     user: "0:0"
#     container_name: spark-history-server
#     command: >
#       bash -c "
#       export SPARK_HISTORY_OPTS='-Dspark.history.fs.logDirectory=file:///events -Dspark.history.fs.update.interval=10s -Dspark.history.ui.maxApplications=100 -Dspark.history.retainedApplications=50 -Dspark.history.ui.port=18080';
#       /opt/spark/sbin/start-history-server.sh;
#       tail -f /opt/spark/logs/spark*.out
#       "
#     depends_on:
#       spark-master:
#         condition: service_healthy
#     environment:
#       - SPARK_NO_DAEMONIZE=true
#       - SPARK_HISTORY_SERVER_MEMORY=${SPARK_DAEMON_MEMORY:-1g}
#     ports:
#       - "${SPARK_HISTORY_SERVER_PORT:-18080}:18080"  # History Server UI
#     networks:
#       - bigdata-net
#     volumes:
#       - ./batch_pipeline/events:/events:ro
#       - ./batch_pipeline/conf/log4j2.properties:/opt/spark/conf/log4j2.properties:ro
#     restart: unless-stopped
#     healthcheck:
#       test: ["CMD", "bash", "-c", "exec 3<>/dev/tcp/localhost/18080 && echo -e 'GET / HTTP/1.1\r\nHost: localhost\r\nConnection: close\r\n\r\n' >&3 && head -1 <&3 | grep -q '200 OK'"]
#       interval: 30s
#       timeout: 10s
#       retries: 3
#       start_period: 60s

#   # FLINK JOBMANAGER
#   flink-jobmanager:
#     image: flink:1.20
#     container_name: flink-jobmanager
#     networks:
#       - bigdata-net
#     command: jobmanager
#     environment:
#       - |
#         FLINK_PROPERTIES=
#         jobmanager.rpc.address: flink-jobmanager
#     ports:
#       - "8082:8081"  # Flink UI

#   # FLINK TASKMANAGER
#   flink-taskmanager:
#     image: flink:1.20
#     container_name: flink-taskmanager
#     networks:
#       - bigdata-net
#     command: taskmanager
#     environment:
#       - |
#         FLINK_PROPERTIES=
#         jobmanager.rpc.address: flink-jobmanager
#     depends_on:
#       - flink-jobmanager


# ###############################################################################
# # Airflow services (minimal, working CeleryExecutor stack)
# ###############################################################################
#   airflow-postgres:
#     image: postgres:15
#     container_name: airflow-postgres
#     networks:
#       - bigdata-net
#     environment:
#       POSTGRES_USER: airflow
#       POSTGRES_PASSWORD: airflow
#       POSTGRES_DB: airflow
#     volumes:
#       - airflow_pgdata:/var/lib/postgresql/data
#     healthcheck:
#       test: ["CMD", "pg_isready", "-U", "airflow"]
#       interval: 10s
#       retries: 5
#       start_period: 5s
#     restart: unless-stopped

#   airflow-redis:
#     image: redis:7
#     container_name: airflow-redis
#     networks:
#       - bigdata-net
#     healthcheck:
#       test: ["CMD", "redis-cli", "ping"]
#       interval: 10s
#       timeout: 5s
#       retries: 5
#       start_period: 5s
#     restart: unless-stopped

#   airflow-webserver:
#     build: ./batch_pipeline/airflow_dockerfile
#     container_name: airflow-webserver
#     networks:
#       - bigdata-net
#     depends_on:
#       - airflow-postgres
#       - airflow-redis
#     ports:
#       - "8080:8080"
#     environment:
#       # Core / DB / Broker
#       AIRFLOW__CORE__EXECUTOR: CeleryExecutor
#       AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
#       AIRFLOW__CELERY__BROKER_URL: redis://airflow-redis:6379/0
#       AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@airflow-postgres/airflow

#       # Security â€” MUST be identical in all components
#       AIRFLOW__WEBSERVER__SECRET_KEY: "${AIRFLOW__WEBSERVER__SECRET_KEY}"
#       AIRFLOW__CORE__FERNET_KEY: "${AIRFLOW__CORE__FERNET_KEY}"

#       # Logging config (no remote logging)
#       AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
#       AIRFLOW__LOGGING__REMOTE_LOGGING: "False"

#       # Celery worker log server (host will be airflow-worker)
#       AIRFLOW__CELERY__WORKER_LOG_SERVER_HOST: airflow-worker
#       AIRFLOW__CELERY__WORKER_LOG_SERVER_PORT: 8793

#       # Optional (reduce noisy example DAGs)
#       AIRFLOW__CORE__LOAD_EXAMPLES: "false"
#       AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "false"
#     volumes:
#       - ./batch_pipeline/airflow/dags:/opt/airflow/dags
#       - ./batch_pipeline/apps:/opt/airflow/apps
#       - ./batch_pipeline/airflow/logs:/opt/airflow/logs
#       - /var/run/docker.sock:/var/run/docker.sock
#     command: >
#       bash -c "airflow db init &&
#                airflow users create --username admin --password sixseven --firstname a --lastname b --role Admin --email admin@example.com || true &&
#                airflow webserver"
#     restart: unless-stopped

#   airflow-scheduler:
#     build: ./batch_pipeline/airflow_dockerfile
#     container_name: airflow-scheduler
#     networks:
#       - bigdata-net
#     depends_on:
#       - airflow-postgres
#       - airflow-redis
#       - airflow-webserver
#     environment:
#       AIRFLOW__CORE__EXECUTOR: CeleryExecutor
#       AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
#       AIRFLOW__CELERY__BROKER_URL: redis://airflow-redis:6379/0
#       AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@airflow-postgres/airflow
#       AIRFLOW__WEBSERVER__SECRET_KEY: "${AIRFLOW__WEBSERVER__SECRET_KEY}"
#       AIRFLOW__CORE__FERNET_KEY: "${AIRFLOW__CORE__FERNET_KEY}"
#       AIRFLOW__CELERY__WORKER_LOG_SERVER_HOST: airflow-worker
#       AIRFLOW__CELERY__WORKER_LOG_SERVER_PORT: 8793
#     volumes:
#       - ./batch_pipeline/airflow/dags:/opt/airflow/dags
#       - ./batch_pipeline/apps:/opt/airflow/apps
#       - ./batch_pipeline/airflow/logs:/opt/airflow/logs
#       - /var/run/docker.sock:/var/run/docker.sock
#     command: airflow scheduler
#     restart: unless-stopped

#   airflow-worker:
#     build: ./batch_pipeline/airflow_dockerfile
#     container_name: airflow-worker
#     networks:
#       - bigdata-net
#     depends_on:
#       - airflow-postgres
#       - airflow-redis
#       - airflow-webserver
#     environment:
#       AIRFLOW__CORE__EXECUTOR: CeleryExecutor
#       AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
#       AIRFLOW__CELERY__BROKER_URL: redis://airflow-redis:6379/0
#       AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@airflow-postgres/airflow
#       AIRFLOW__WEBSERVER__SECRET_KEY: "${AIRFLOW__WEBSERVER__SECRET_KEY}"
#       AIRFLOW__CORE__FERNET_KEY: "${AIRFLOW__CORE__FERNET_KEY}"
#       AIRFLOW__CELERY__WORKER_LOG_SERVER_HOST: airflow-worker
#       AIRFLOW__CELERY__WORKER_LOG_SERVER_PORT: 8793
#       AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
#     volumes:
#       - ./batch_pipeline/airflow/dags:/opt/airflow/dags
#       - ./batch_pipeline/apps:/opt/airflow/apps
#       - ./batch_pipeline/airflow/logs:/opt/airflow/logs
#       - /var/run/docker.sock:/var/run/docker.sock
#     command: airflow celery worker
#     restart: unless-stopped



#   # mariadb:
#   #   image: mariadb:10.11
#   #   container_name: matomo-mariadb
#   #   environment:
#   #     MYSQL_ROOT_PASSWORD: admin
#   #     MYSQL_DATABASE: admin
#   #     MYSQL_USER: admin
#   #     MYSQL_PASSWORD: admin
#   #   volumes:
#   #     - db_data:/var/lib/mysql
    

#   # matomo:
#   #   image: matomo:latest
#   #   depends_on:
#   #     - mariadb
#   #   ports:
#   #     - "80:80"         # HTTP
#   #     - "443:443"       # HTTPS
#   #   environment:
#   #     MATOMO_DATABASE_HOST: mariadb
#   #     MATOMO_DATABASE_USERNAME: admin
#   #     MATOMO_DATABASE_PASSWORD: admin
#   #     MATOMO_DATABASE_DBNAME: admin
#   #   volumes:
#   #     - matomo_data:/var/www/html
#   #     - ./matomo_config/certs:/etc/matomo/certs:ro
#   #     - ./matomo_config/ssl.conf:/etc/apache2/sites-enabled/ssl.conf:ro
#   #   command: >
#   #     bash -c "
#   #       a2enmod ssl &&
#   #       apache2-foreground
#   #     "



volumes:
  clickhouse_data:
  clickhouse_logs:
  # minio_data:
  # airflow_pgdata:
  # spark-recovery:

networks:
  bigdata-net:
    driver: bridge